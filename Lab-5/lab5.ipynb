{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647eff04-b45e-4cd9-9887-fbcc73f8502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement convolution operation for a sample image of shape (H=6, W=6, C=1) with a\n",
    "#random kernel of size (3,3) using torch.nn.functional.conv2d.What is the dimension of the output image? Apply, various values for parameter stride=1\n",
    "'''and note the change in the dimension of the output image. Arrive at an equation for the\n",
    "output image size with respect to the kernel size and stride and verify your answer with  code. Now, repeat the exercise by changing padding parameter. Obtain a formula using\n",
    "kernel, stride, and padding to get the output image size. What is the total number of\n",
    "parameters in your network? Verify with code.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a851f27-492a-4a8d-a925-0db3ecf1ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7052, 0.0011, 0.6545, 0.7284, 0.9724, 0.8017],\n",
      "        [0.2665, 0.7070, 0.1184, 0.3428, 0.3115, 0.1859],\n",
      "        [0.8497, 0.3080, 0.7402, 0.7722, 0.7764, 0.8089],\n",
      "        [0.7511, 0.1458, 0.4076, 0.7078, 0.2020, 0.8551],\n",
      "        [0.0653, 0.4380, 0.0450, 0.7740, 0.3332, 0.7223],\n",
      "        [0.0494, 0.6175, 0.3621, 0.0624, 0.5676, 0.6661]])\n",
      "image shape: torch.Size([1, 6, 6])\n",
      "tensor([[[0.7052, 0.0011, 0.6545, 0.7284, 0.9724, 0.8017],\n",
      "         [0.2665, 0.7070, 0.1184, 0.3428, 0.3115, 0.1859],\n",
      "         [0.8497, 0.3080, 0.7402, 0.7722, 0.7764, 0.8089],\n",
      "         [0.7511, 0.1458, 0.4076, 0.7078, 0.2020, 0.8551],\n",
      "         [0.0653, 0.4380, 0.0450, 0.7740, 0.3332, 0.7223],\n",
      "         [0.0494, 0.6175, 0.3621, 0.0624, 0.5676, 0.6661]]])\n",
      "kernel: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "outimage= tensor([[[ 5.8347,  6.9093,  5.1968],\n",
      "         [ 6.7775, 11.8359,  6.7775],\n",
      "         [ 5.1968,  6.9093,  5.8347]]])\n",
      "Output image shape with padding=0: torch.Size([1, 1, 1])\n",
      "Output image shape with padding=1: torch.Size([1, 3, 3])\n",
      "Output image shape with padding=2: torch.Size([1, 5, 5])\n",
      "Output image shape with padding=3: torch.Size([1, 7, 7])\n",
      "Total number of parameters in the network: 36\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "img = torch.rand(6,6)\n",
    "print(img)\n",
    "img = torch.unsqueeze(img,dim=0)\n",
    "print(f\"image shape: {img.shape}\")\n",
    "print(img)\n",
    "kernel = torch.ones(3,3)\n",
    "print(f\"kernel: {kernel}\")\n",
    "kernel = torch.unsqueeze(img,dim=0)\n",
    "kernel = torch.unsqueeze(img,dim=0)\n",
    "outimage = F.conv2d(img, kernel, stride=1, padding=1)\n",
    "print(\"outimage=\", outimage)\n",
    "for padding in range(4):  # Try paddings from 0 to 3\n",
    "    out_image = F.conv2d(img, kernel, stride=1, padding=padding)\n",
    "    print(f\"Output image shape with padding={padding}: {out_image.shape}\")\n",
    "\n",
    "# Formula for output image size with respect to kernel size, stride, and padding:\n",
    "# output_size = ((input_size - kernel_size + 2 * padding) / stride) + 1\n",
    "\n",
    "# Calculate total number of parameters in the network\n",
    "total_params = kernel.numel()  # Number of parameters in the kernel\n",
    "print(f\"Total number of parameters in the network: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccb20e-eb4b-4d2d-82ea-8e2726981027",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Apply torch.nn.Conv2d to the input image of Qn 1 with out-channel=3 and observe the\n",
    "output. Implement the equivalent of torch.nn.Conv2d using the torch.nn.functional.conv2D\n",
    "to get the same output. You may ignore bias'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90662fde-247f-4d22-af04-9109a1033924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape using torch.nn.Conv2d: torch.Size([1, 3, 4, 4])\n",
      "Output shape using torch.nn.functional.conv2d: torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "img = torch.rand(1, 1, 6, 6)  \n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "output_conv = conv_layer(img)\n",
    "print(\"Output shape using torch.nn.Conv2d:\", output_conv.shape)\n",
    "kernel_weights = torch.randn(3, 1, 3, 3)\n",
    "output_conv_func = torch.nn.functional.conv2d(img, kernel_weights, padding=0)\n",
    "print(\"Output shape using torch.nn.functional.conv2d:\", output_conv_func.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a28fcd-6700-45fd-8ca6-9f945b1cbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Implement CNN for classifying digits in MNIST dataset using PyTorch. Display the\n",
    "classification accuracy in the form of a Confusion matrix. Verify the number of learnable\n",
    "parameters in the model.\n",
    "Training a CNN on an image dataset is similar to training a basic multi-layer feed-forward\n",
    "network on numerical data as outlined below.\n",
    "Define model architecture\n",
    "Load dataset from disk\n",
    "Loop over epochs and batches\n",
    "Make predictions and compute loss\n",
    "Properly zero our gradient, perform backpropagation, and update model parameters'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2007eef-aaa8-40ba-854b-f2ecf1d9d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.4720\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2619\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2023\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        self.clf_head = nn.Sequential(nn.Linear(64, 20),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(20, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        return self.clf_head(features.view(x.size(0), -1))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = CNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of learnable parameters in the model: {total_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3f74c-4037-43cd-9e24-1b0f3317f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Modify CNN of Qn. 3 to reduce the number of parameters in the network. Draw a plot of\n",
    "percentage drop in parameters vs accuracy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905d16e-01d4-4f40-a8c9-521c192e676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ReducedCNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=3),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2), stride=2)\n",
    "        )\n",
    "\n",
    "        self.clf_head = nn.Sequential(nn.Linear(32, 20), \n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(20, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        return self.clf_head(features.view(x.size(0), -1))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = ReducedCNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of learnable parameters in the model: {total_params}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
